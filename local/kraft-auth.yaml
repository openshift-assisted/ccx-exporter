---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kraft-configuration
  labels:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
data:
  kafka_server_jaas.conf: |-
    KafkaServer {
        org.apache.kafka.common.security.scram.ScramLoginModule required
        username="admin"
        password="admin-secret"
        user_admin="admin-secret";
    };
  server.properties: |-
    ############################# Server Basics #############################

    # The role of this server. Setting this puts us in KRaft mode
    process.roles=broker,controller

    # The node id associated with this instance's roles
    node.id=1

    # The connect string for the controller quorum
    controller.quorum.voters=1@kraft-0.kraft:9093

    ############################# Socket Server Settings #############################

    # The address the socket server listens on.
    # Combined nodes (i.e. those with `process.roles=broker,controller`) must list the controller listener here at a minimum.
    # If the broker listener is not defined, the default listener will use a host name that is equal to the value of java.net.InetAddress.getCanonicalHostName(),
    # with PLAINTEXT listener name, and port 9092.
    #   FORMAT:
    #     listeners = listener_name://host_name:port
    #   EXAMPLE:
    #     listeners = PLAINTEXT://your.host.name:9092
    listeners=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:32323

    # Name of listener used for communication between brokers.
    inter.broker.listener.name=PLAINTEXT

    # Listener name, hostname and port the broker will advertise to clients.
    # If not set, it uses the value for "listeners".
    advertised.listeners=PLAINTEXT://kraft-0.kraft:9092,EXTERNAL://localhost:32323

    # A comma-separated list of the names of the listeners used by the controller.
    # If no explicit mapping set in `listener.security.protocol.map`, default will be using PLAINTEXT protocol
    # This is required if running in KRaft mode.
    controller.listener.names=CONTROLLER

    # Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details
    listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT

    # The number of threads that the server uses for receiving requests from the network and sending responses to the network
    num.network.threads=3

    # The number of threads that the server uses for processing requests, which may include disk I/O
    num.io.threads=8

    # The send buffer (SO_SNDBUF) used by the socket server
    socket.send.buffer.bytes=102400

    # The receive buffer (SO_RCVBUF) used by the socket server
    socket.receive.buffer.bytes=102400

    # The maximum size of a request that the socket server will accept (protection against OOM)
    socket.request.max.bytes=104857600

    # List of enabled mechanisms, can be more than one
    sasl.enabled.mechanisms=SCRAM-SHA-512

    sasl.mechanism.inter.broker.protocol=PLAINTEXT
    sasl.mechanism.controller.protocol=PLAIN

    listener.name.EXTERNAL.sasl.enabled.mechanisms=SCRAM-SHA-512

    authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer

    ############################# Topic Basics #############################

    auto.create.topics.enable=true

    ############################# Log Basics #############################

    # A comma separated list of directories under which to store log files
    log.dirs=/opt/data/kraft/combined-logs

    # The default number of log partitions per topic. More partitions allow greater
    # parallelism for consumption, but this will also result in more files across
    # the brokers.
    num.partitions=1

    # The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
    # This value is recommended to be increased for installations with data dirs located in RAID array.
    num.recovery.threads.per.data.dir=1

    ############################# Internal Topic Settings  #############################
    # The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
    # For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
    offsets.topic.replication.factor=1
    transaction.state.log.replication.factor=1
    transaction.state.log.min.isr=1

    ############################# Log Retention Policy #############################

    # The following configurations control the disposal of log segments. The policy can
    # be set to delete segments after a period of time, or after a given size has accumulated.
    # A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
    # from the end of the log.

    # The minimum age of a log file to be eligible for deletion due to age
    log.retention.hours=168

    # A size-based retention policy for logs. Segments are pruned from the log unless the remaining
    # segments drop below log.retention.bytes. Functions independently of log.retention.hours.
    #log.retention.bytes=1073741824

    # The maximum size of a log segment file. When this size is reached a new log segment will be created.
    log.segment.bytes=1073741824

    # The interval at which log segments are checked to see if they can be deleted according
    # to the retention policies
    log.retention.check.interval.ms=300000

    super.users=User:ANONYMOUS;User:admin
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kraft-scripts
  labels:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
data:
  start.sh: |
    #!/bin/bash

    export KAFKA_OPTS=-Djava.security.auth.login.config=/opt/data/kraft/config/kafka_server_jaas.conf

    mkdir -p /opt/data/kraft/config
    cp /tmp/kraft/server.properties /opt/data/kraft/config/server.properties
    cp /tmp/kraft/kafka_server_jaas.conf /opt/data/kraft/config/kafka_server_jaas.conf

    export suuid=$(/opt/kafka/bin/kafka-storage.sh random-uuid)
    /opt/kafka/bin/kafka-storage.sh format -t $suuid -c /opt/data/kraft/config/server.properties --add-scram 'SCRAM-SHA-512=[name=admin,password=admin-secret]'
    
    /opt/kafka/bin/kafka-server-start.sh /opt/data/kraft/config/server.properties
---
apiVersion: v1
kind: Service
metadata:
  name: kraft
  labels:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: controller
    port: 9093
    targetPort: 9093
  - name: client
    port: 9092
    targetPort: 9092
  selector:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
---
apiVersion: v1
kind: Service
metadata:
  name: kraft-external
  labels:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
spec:
  type: NodePort
  ports:
  - name: external
    port: 32323
    targetPort: 32323
    nodePort: 32323
  selector:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kraft
  labels:
    app.kubernetes.io/name: kraft
    app.kubernetes.io/instance: ccx-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kraft
      app.kubernetes.io/instance: ccx-exporter
  serviceName: kraft
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kraft
        app.kubernetes.io/instance: ccx-exporter
    spec:
      terminationGracePeriodSeconds: 30
      containers:
      - name: kraft
        image: apache/kafka:3.8.0
        imagePullPolicy: "IfNotPresent"
        command:
        - /bin/bash
        args:
        - -c
        - /opt/kraft/scripts/start.sh
        ports:
        - name: controller
          containerPort: 9093
        - name: client
          containerPort: 9092
        - name: external
          containerPort: 32323
        resources:
          limits: {}
          requests: {}
        volumeMounts:
        - name: start-scripts
          mountPath: /opt/kraft/scripts
        - name: kraft
          mountPath: /opt/data/kraft
        - name: config
          mountPath: /tmp/kraft
      volumes:
      - name: start-scripts
        configMap:
          name: kraft-scripts
          defaultMode: 0755
      - name: config
        configMap:
          name: kraft-configuration
  volumeClaimTemplates:
  - metadata:
      name: kraft
      labels:
        app.kubernetes.io/name: kraft
        app.kubernetes.io/instance: ccx-exporter
    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: "4Gi"
